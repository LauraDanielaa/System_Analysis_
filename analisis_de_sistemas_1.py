# -*- coding: utf-8 -*-
"""analisis de sistemas_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tcaz1huqTsHxJM0Y4GF2GlsfJl9SX63l

Workshop Definition:
Welcome to the first workshop of Systems Analysis course. Letâ€™s funny me with a biological exercise.

Imagine you have been hired as data analyst in an important biotechnology company. Your boss, science chief officer, want to get some patterns in genomic data, sometimes called motifs.

Here you will have some tasks in order to complete this workshop: Create a dummy database of genetic sequences composed of nucleotide bases (A, C, G, T), where each sequence must have between 10 and 20 bases. Your database must be composed for 50.000 genetic sequences.

---> Get the motifs (must repeated sequence) of size 6 and 8. Use the Shannon Entropy measurement to filter sequences with not a good variance level. Get again the motifs of size 6 and 8.

Write some conclusions based on your analysis. Write any technical concern/decision/difficulty you think is relevant regarding your work. You must deliver a full report detailing each one of the previous steps. For steeps 1 to 4 you must describe the algorithms you propose and let an screenshot about the code and the output of the code. I strongly recommend you to use a Jupyter Notebook or a COLAB to write/execute your code.
"""

#crear una base de datos dummy (Dummy data base)
import random

def create_sequence():
    nucleotid_bases = ['A', 'C', 'G', 'T']
    size_sequence = random.randint(10, 20) #las cadenas deben de tener 10 a 20 bases nucleotidas
    new_sequence = [nucleotid_bases[random.randint(0,3)] for i in range (size_sequence)]
    return "".join(new_sequence)

print(create_sequence())

#Crear la base de datos dummy
def create_database(length):
    db_size = length
    data_base ={create_sequence() for i in range (db_size)}
    return data_base

def get_combination(n, sequences, bases):
  if n == 1:
    return[sequence+base for sequence in sequences for base in bases]
  else:
    sequence = [sequence + base for sequence in sequences for base in bases]
    return get_combination(n-1, sequence, bases)

# Procedimiento para calcular la moda
def count_motif(motif, sequences_db):
    count = 0
    for sequence in sequences_db:
        count += sequence.count(motif)
    return count

def get_motif(motif_size, sequences_db):
    nucletid_bases = ["A", "C", "G", "T"]
    combinations = get_combination(motif_size, [""], nucletid_bases)
    max_counter = 0
    motif_winner = ""

#Condicion para calcular el motif
    for motif_candidate in combinations:
        temp_conter = count_motif(motif_candidate, sequences_db)
        if temp_conter > max_counter:
            max_counter = temp_conter
            motif_winner = motif_candidate
    return motif_winner,max_counter

#Imprime los mofits que mas se repite de cadena de 6 y 8 bases nucleotidas
print(get_motif(6, create_database(50000)))

print(get_motif(8, create_database(50000)))

"""
Entropia de shanon



"""

#Imprime todos las cadenas de bases nucleotidas que se repiten de 6 y 8
for size in [6, 8]:
    print(f"\nMotifs of size: {size}")
for i in range(10):
     print(get_motif(size, create_database(50000)))

#print(get_motif(size, create_database(50000)))

import math
from math import log2
from collections import Counter


def calculate_shannon_entrophy(sequence: str) -> float:

def filter_shannon(sequence: str) -> bool:

    # add the condition where if it is true the sequence will be used


    return calculate_shannon_entrophy(sequence)

    # ADD here the condition to filter the sequences

    for size in [6,8] :
        print(f"\nArter filter, motifs of size: {size}")
        for i in range(10):
            dataset = create_database(50000)
            dataset = list(filter(filter_shannon, dataset))
            print(f"Dataset size: {len(dataset)}, Motif : {get_motif(size, dataset)}")

for size in [6, 8]:
    print(f"\nArter filter, motifs of size: {size}")
    for i in range(10):
        dataset = create_dataset(50000)
        dataset = list(filter(filter_shannon, dataset))
        print(f"Dataset size: {len(dataset)}, Motif: {get_motif(size, dataset)}")